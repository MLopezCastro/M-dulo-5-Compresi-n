¬°Perfecto, Marcelo! üöÄ Te actualizo el **README ‚Äì Parte 1** con tus resultados reales de tama√±os y tiempos. As√≠ queda documentado el benchmark üëá

---

# Parte 1 ‚Äî Dataset sint√©tico (100 MB), exportaci√≥n y comparaci√≥n de formatos

Este m√≥dulo genera un CSV de ~100 MB con columnas `fecha`, `regi√≥n`, `id`, `monto`, `cliente`; lo exporta a varios formatos y compara tama√±os/tiempos de lectura.

## üìÇ Estructura del proyecto

```
Modulo 5 - Compresi√≥n/
‚îú‚îÄ .venv/
‚îú‚îÄ data/
‚îÇ  ‚îî‚îÄ ventas_100mb.csv                  # generado en Parte 1
‚îú‚îÄ outputs/
‚îÇ  ‚îú‚îÄ csv/
‚îÇ  ‚îÇ  ‚îú‚îÄ ventas_100mb.csv
‚îÇ  ‚îÇ  ‚îî‚îÄ ventas_100mb.csv.gz
‚îÇ  ‚îú‚îÄ parquet/
‚îÇ  ‚îÇ  ‚îî‚îÄ ventas_100mb.parquet
‚îÇ  ‚îî‚îÄ parquet_partitioned/
‚îÇ     ‚îî‚îÄ mes=YYYY-MM/part-*.parquet
‚îú‚îÄ make_100mb_csv.py
‚îú‚îÄ exportar_formatos.py
‚îú‚îÄ benchmark_formatos.py
‚îú‚îÄ requirements.txt
‚îî‚îÄ .gitignore
```

> **Nota GitHub:** `outputs/` y `data/*.csv` est√°n ignorados en `.gitignore` para evitar subir archivos grandes.

## ‚ñ∂Ô∏è Requisitos e instalaci√≥n

```powershell
# En la carpeta del proyecto
py -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

`requirements.txt`:

```
pandas
numpy
pyarrow
```

## 1) Generar dataset (~100 MB)

Crea un CSV de prueba en `data/ventas_100mb.csv`:

```powershell
python make_100mb_csv.py
```

## 2) Exportar a m√∫ltiples formatos

Genera:

* CSV sin comprimir
* CSV gzip
* Parquet (√∫nico archivo)
* Parquet **particionado por mes** (`mes=YYYY-MM`)

```powershell
python exportar_formatos.py
```

## 3) Benchmark (tama√±o y tiempos de lectura)

Mide:

* **Tama√±o en disco** (MB)
* **Tiempo de lectura total**
* **Tiempo de lectura filtrado por un mes** (ej. `2023-07`)

```powershell
python benchmark_formatos.py
```

### ‚úÖ Resultados obtenidos

**Tama√±o en disco:**

* CSV plano              : 124.70 MB
* CSV gzip               : 33.75 MB
* Parquet                : 29.74 MB
* Parquet particionado   : 49.94 MB

**Tiempo de lectura total:**

* CSV plano              : 1.27 s
* CSV gzip               : 1.58 s
* Parquet                : 0.40 s
* Parquet particionado   : 0.39 s

**Tiempo de lectura con filtro (mes=2023-07):**

* CSV plano              : 1.29 s, filas=254,540
* CSV gzip               : 1.60 s, filas=254,540
* Parquet                : 0.40 s, filas=254,540
* Parquet particionado   : 0.04 s, filas=254,540

### üìä Comparaci√≥n en tabla

| Formato              | Tama√±o (MB) | Lectura total (s) | Lectura filtro mes (s) | Filas mes |
| -------------------- | ----------- | ----------------- | ---------------------- | --------- |
| CSV plano            | 124.70      | 1.27              | 1.29                   | 254,540   |
| CSV gzip             | 33.75       | 1.58              | 1.60                   | 254,540   |
| Parquet              | 29.74       | 0.40              | 0.40                   | 254,540   |
| Parquet particionado | 49.94       | 0.39              | **0.04**               | 254,540   |

---

## üß™ Conclusiones r√°pidas

* **Parquet** es m√°s compacto y veloz que CSV.
* **CSV gzip** reduce mucho tama√±o, pero penaliza un poco la velocidad de lectura.
* **Parquet particionado** sobresale al filtrar: carga solo la carpeta del mes y es **~10√ó m√°s r√°pido** que leer todo.

---



